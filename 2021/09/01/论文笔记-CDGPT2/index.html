

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Joe">
  <meta name="keywords" content="">
  
  <title>论文笔记-CDGPT2 - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.6.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"joexy312.github.io","root":"/","version":"1.8.10","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 20vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Joe</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="论文笔记-CDGPT2">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-09-01 13:00" pubdate>
        2021年9月1日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.6k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      52
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">论文笔记-CDGPT2</h1>
            
            <div class="markdown-body">
              <h2 id="论文简述"><a href="#论文简述" class="headerlink" title="论文简述"></a>论文简述</h2><p>本文提出了一个conditioned transformer-based model(CDGPT2)，即‘conditioned distil generative pre-trained transformer2,’<strong>根据X-Ray image生成完整的报告</strong><br>数据集：IU-XRay。  </p>
<p><img src="/images/pasted-19.png" srcset="/img/loading.gif" lazyload alt="网络整体结构"></p>
<h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="本文用到的模型"><a href="#本文用到的模型" class="headerlink" title="本文用到的模型"></a>本文用到的模型</h3><p><strong>Visual Model</strong>:</p>
<ul>
<li>ChexNet:image to visual features, <strong>DenseNet121</strong> model pretrained on ChestX-ray14 dataset</li>
</ul>
<p><strong>NLP</strong>:</p>
<ul>
<li>MEDLINE/PubMed:tags embeddings</li>
<li><a target="_blank" rel="noopener" href="https://www.freesion.com/article/66311274765/">分词器Tokenizer</a>：Tokenizer 是一种用于自然语言处理的类，其具体的功能是把一个词（中文单个字或者词组认为是一个词）转化为一个正整数，于是一个文本就变成了一个序列。</li>
<li>GPT2_tokenizer: captions to “targets” 把单词转换为字节对编码（？）</li>
</ul>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">self<span class="hljs-selector-class">.x_path</span>, self<span class="hljs-selector-class">.y</span> = df<span class="hljs-selector-attr">[<span class="hljs-string">&quot;Image Index&quot;</span>]</span><span class="hljs-selector-class">.values</span>, self<span class="hljs-selector-class">.tokenizer_wrapper</span><span class="hljs-selector-class">.GPT2_encode</span>(<br>    df<span class="hljs-selector-attr">[self.class_names]</span>.values<br>    , max_length=<span class="hljs-number">1000</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(<span class="hljs-keyword">self</span>, idx)</span></span><span class="hljs-symbol">:</span><br>    batch_x_path = <span class="hljs-keyword">self</span>.x_path[idx * <span class="hljs-keyword">self</span>.<span class="hljs-symbol">batch_size:</span>(idx + <span class="hljs-number">1</span>) * <span class="hljs-keyword">self</span>.batch_size]<br>    batch_x = np.asarray([<span class="hljs-keyword">self</span>.load_image(x_path) <span class="hljs-keyword">for</span> x_path <span class="hljs-keyword">in</span> batch_x_path])<br>    batch_x = <span class="hljs-keyword">self</span>.transform_batch_images(batch_x)<br>    batch_y = <span class="hljs-keyword">self</span>.y[idx * <span class="hljs-keyword">self</span>.<span class="hljs-symbol">batch_size:</span>(idx + <span class="hljs-number">1</span>) * <span class="hljs-keyword">self</span>.batch_size]<br>    <span class="hljs-keyword">return</span> batch_x, batch_y, batch_x_path<br>    <br>img, target, _ = <span class="hljs-keyword">next</span>(train_generator)<br></code></pre></td></tr></table></figure>

<ul>
<li>decoder: distilgpt2<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">decoder = TFGPT2LMHeadModel.from_pretrained(<span class="hljs-string">&#x27;distilgpt2&#x27;</span>, <span class="hljs-attribute">from_pt</span>=<span class="hljs-literal">True</span>, <span class="hljs-attribute">resume_download</span>=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure></li>
</ul>
<h3 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/265108616">Attention注意力机制与self-attention自注意力机制</a></p>
<h4 id="注意力机制模型"><a href="#注意力机制模型" class="headerlink" title="注意力机制模型"></a>注意力机制模型</h4><p><img src="/images/pasted-20.png" srcset="/img/loading.gif" lazyload alt="注意力机制模型"></p>
<h4 id="Attention计算过程"><a href="#Attention计算过程" class="headerlink" title="Attention计算过程"></a>Attention计算过程</h4><p>至于Attention机制的具体计算过程，如果对目前大多数方法进行抽象的话，可以将其归纳为两个过程：<strong>第一个过程是根据Query和Key计算权重系数</strong>，<strong>第二个过程根据权重系数对Value进行加权求和</strong>。而第一个过程又可以细分为两个阶段：第一个阶段根据Query和Key计算两者的相似性或者相关性；第二个阶段对第一阶段的原始分值进行归一化处理；这样，可以将Attention的计算过程抽象为如图展示的三个阶段。</p>
<p><img src="/images/pasted-21.png" srcset="/img/loading.gif" lazyload alt="求相似度的常见方式"></p>
<p>第二阶段引入类似SoftMax的计算方式对第一阶段的得分进行数值转换，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过SoftMax的内在机制更加突出重要元素的权重。即一般采用如下公式计算：</p>
<p><img src="/images/pasted-22.png" srcset="/img/loading.gif" lazyload alt="softmax"></p>
<p>第二阶段的计算结果$a_i$即为$value_i$对应的权重系数，然后进行加权求和即可得到Attention数值：</p>
<p><img src="/images/pasted-23.png" srcset="/img/loading.gif" lazyload alt="attention"></p>
<p>从本质上理解，Attention是从大量信息中有筛选出少量重要信息，并聚焦到这些重要信息上，忽略大多不重要的信息。权重越大越聚焦于其对应的Value值上，即权重代表了信息的重要性，而Value是其对应的信息。</p>
<h4 id="Self-attention自注意力机制"><a href="#Self-attention自注意力机制" class="headerlink" title="Self-attention自注意力机制"></a>Self-attention自注意力机制</h4><p>自注意力机制是注意力机制的变体，其减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。自注意力机制在文本中的应用，主要是通过计算单词间的互相影响，来解决长距离依赖问题。自注意力机制的计算过程：<br>1.将输入单词转化成嵌入向量；<br>2.根据嵌入向量得到q，k，v三个向量；<br>3.为每个向量计算一个score：score =q . k ；<br>4.为了梯度的稳定，Transformer使用了score归一化；<br>5.对score施以softmax激活函数；<br>6.softmax点乘Value值v，得到加权的每个输入向量的评分v；<br>7.相加之后得到最终的输出结果z</p>
<h3 id="字节对编码"><a href="#字节对编码" class="headerlink" title="字节对编码"></a>字节对编码</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/136138225">GPT-2：结构、数据和字节对编码</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/369625931">字节对编码-Byte Pair Encoding</a></p>
<blockquote>
<p>在自然语言处理模型中，模型的输入通常是句子序列，例如“我上周去了纽约”。该序列由令牌组成。在旧的语言模型中，标记通常是由空格分隔的单词和标点符号，例如 [“i”, “went”, “to”, “new”, “york”, “last”, “week”, “.”]. word2vec模型使用的是这种标记化方法。在信息论中，字节对编码（BPE）或图编码是数据压缩的一种简单形式，其中最常见的一对连续字节数据被替换为该数据中不存在的字节。 在Wikipedia上，有一个很好的在单个字符串上使用BPE的示例。 它还被用于自然语言处理模型中，例如Transformer（在标准WMT 2014英语-德语数据集上进行训练）和GPT-2，以对单词序列进行标记化。</p>
</blockquote>
<h3 id="GPT-2解读"><a href="#GPT-2解读" class="headerlink" title="GPT-2解读"></a>GPT-2解读</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/79714797">完全图解GPT-2：看完这篇就够了（一）
</a></p>
<blockquote>
<p>GPT-2 可以处理最长 1024 个单词的序列。每个单词都会和它的前续路径一起「流过」所有的解码器模块。</p>
</blockquote>
<h4 id="输入编码Token-Embeddings-wte"><a href="#输入编码Token-Embeddings-wte" class="headerlink" title="输入编码Token Embeddings(wte)"></a>输入编码Token Embeddings(wte)</h4><p><img src="/images/pasted-24.png" srcset="/img/loading.gif" lazyload alt="wte"></p>
<ul>
<li>每一行都是一个词嵌入向量，即表征某个单词，并捕获其意义的数字列表;</li>
<li>嵌入向量的长度和 GPT-2 模型的大小有关，最小的模型使用了长为 768 的嵌入向量来表征一个单词。</li>
</ul>
<p>实现：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs lua">       <span class="hljs-built_in">self</span>.wte = TFSharedEmbeddings(<br>            <span class="hljs-built_in">config</span>.vocab_size, position_ids = tf.range(past_length, input_shape[<span class="hljs-number">-1</span>] + past_length, dtype=tf.int32)[tf.newaxis, :]  # <span class="hljs-string">[[0, 1, 2, ..., 998]]</span><br><span class="hljs-built_in">config</span>.hidden_size, initializer_range=<span class="hljs-built_in">config</span>.initializer_range, name=<span class="hljs-string">&quot;wte&quot;</span><br>        )  #<span class="hljs-number">50257</span>，<span class="hljs-number">768</span><br></code></pre></td></tr></table></figure>

<p>TFSharedEmbeddings：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">TFSharedEmbeddings</span>(<span class="hljs-params">tf.keras.layers.Layer</span>):</span><br>    <span class="hljs-string">&quot;&quot;&quot;Construct shared token embeddings.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, vocab_size, hidden_size, initializer_range=<span class="hljs-literal">None</span>, **kwargs</span>):</span><br>        <span class="hljs-built_in">super</span>().__init__(**kwargs)<br>        self.vocab_size = vocab_size<br>        self.hidden_size = hidden_size<br>        self.initializer_range = hidden_size ** -<span class="hljs-number">0.5</span> <span class="hljs-keyword">if</span> initializer_range <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> initializer_range<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">build</span>(<span class="hljs-params">self, input_shape</span>):</span><br>        <span class="hljs-string">&quot;&quot;&quot;Build shared word embedding layer</span><br><span class="hljs-string">        Shared weights logic adapted from</span><br><span class="hljs-string">            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.weight = self.add_weight(<br>            <span class="hljs-string">&quot;weight&quot;</span>, shape=[self.vocab_size, self.hidden_size], initializer=get_initializer(self.initializer_range)<br>        )<br>        <span class="hljs-built_in">super</span>().build(input_shape)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">call</span>(<span class="hljs-params">self, inputs, mode=<span class="hljs-string">&quot;embedding&quot;</span></span>):</span><br>        <br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&quot;embedding&quot;</span>:<br>            <span class="hljs-keyword">return</span> self._embedding(inputs)<br>        <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&quot;linear&quot;</span>:<br>            <span class="hljs-keyword">return</span> self._linear(inputs)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;mode &#123;&#125; is not valid.&quot;</span>.<span class="hljs-built_in">format</span>(mode))<br></code></pre></td></tr></table></figure>

<h4 id="位置编码Position-Encodings-wpe"><a href="#位置编码Position-Encodings-wpe" class="headerlink" title="位置编码Position Encodings(wpe)"></a>位置编码Position Encodings(wpe)</h4><h2 id="对本文模型的理解"><a href="#对本文模型的理解" class="headerlink" title="对本文模型的理解"></a>对本文模型的理解</h2><p><img src="/images/pasted-25.png" srcset="/img/loading.gif" lazyload alt="网络整体结构"></p>
<ul>
<li><strong>网络组成</strong>：网络包含encoder部分——根据图像输出<strong>视觉特征</strong>和<strong>语义特征</strong>，以及decoder部分——<strong>生成单词</strong>。  <ul>
<li>encoder是一个预训练的Chexnet，本文通过微调来输出对105个tags的预测(原网络最后一层输出14个tag，作者认为是不够的)。Chexnet的输出结果为0-1之间的数（$105\times 1$的列向量），代表对105个tag的预测分数(confidence score)。用来与对应的预训练word2vec词嵌入相乘，词嵌入在大型的医学语料库中预训练，和视觉特征一起输入decoder。微调chexnet的时候的损失函数是交叉熵，微调完了之后visual model的权重和词嵌入在GPT2训练时都是固定的。 </li>
<li>decoder是一个预训练的distilGPT2,通过视觉特征和tags embedding的调整，输出完整报告。</li>
</ul>
</li>
<li>decoder输入包含三个部分：<ul>
<li>图像输入预训练Chexnet，网络倒数第三层输出特征图(batchsize, 49, 1024) <strong>输入一（visual features）</strong> </li>
<li>tags通过预训练word2vec转为词嵌入，与chexnet最后一层输出的预测分数相乘，获得加权的tags的词嵌入(batchsize,105,400)<strong>输入二（semantic features）</strong></li>
<li>caption的字节对编码前999位(batchsize, 999)<strong>输入三 （Token Embeddings）</strong></li>
</ul>
</li>
<li><strong>网络目标</strong>：网络要实现的是输入图像，输出诊断文本(Caption),也就是Impressions+Findings</li>
<li><strong>GPT2部分：</strong><ul>
<li>本文跟普通GPT2的一个区别在于输入是xyz三个部分</li>
<li>distilGPT-2模型的训练结果还包含两个权值矩阵：嵌入矩阵和位置编码矩阵</li>
<li>transformer输出为(batchsize, 999, 768),然后与wte相乘，结果尺寸为(batchsize,999,50257)，也就是999个位置分别对应词汇表的权重，最大的即是当前位置的词（简单情况下）</li>
<li>GPT2训练过程：输入单词进入transformer之前，需要查找单词对应的嵌入向量，然后加上位置编码，才能输入transformer进行下一步操作。</li>
</ul>
</li>
<li><strong>数据集</strong>包含7430张图像，all_data_csv是一个（7430,6）的表格，横坐标是数据，纵坐标包括Image index，Patient ID，Findings，Impression，caption和Manual Tags,caption是Impression+Findings，也是输出的目标内容。</li>
</ul>
<h2 id="源码阅读"><a href="#源码阅读" class="headerlink" title="源码阅读"></a>源码阅读</h2><p><a target="_blank" rel="noopener" href="https://github.com/omar-mohamed/GPT2-Chest-X-Ray-Report-Generation">源码地址</a></p>
<h3 id="初始化参数部分"><a href="#初始化参数部分" class="headerlink" title="初始化参数部分"></a>初始化参数部分</h3><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">FLAGS = arg<span class="hljs-constructor">Handler()</span><br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">FLAGS</span>.</span></span>set<span class="hljs-constructor">Defaults()</span><br>tf.keras.backend.set<span class="hljs-constructor">_learning_phase(1)</span>  # Sets the learning phase <span class="hljs-keyword">to</span> a fixed value<br></code></pre></td></tr></table></figure>

<h3 id="分词器"><a href="#分词器" class="headerlink" title="分词器"></a>分词器</h3><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/390821442">tokenizer的使用介绍</a><br><strong>其主要的任务是将文本输入转化为模型可以接受的输入，因为模型只能输入数字，所以tokenizer会将文本输入转化为数值型的输入</strong></p>
<figure class="highlight oxygene"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs oxygene">tokenizer_wrapper = TokenizerWrapper(<span class="hljs-keyword">FLAGS</span>.all_data_csv, <span class="hljs-keyword">FLAGS</span>.csv_label_columns[<span class="hljs-number">0</span>],<br>                                     <span class="hljs-keyword">FLAGS</span>.max_sequence_length, <span class="hljs-keyword">FLAGS</span>.tokenizer_vocab_size)<br>```  <br><br><span class="hljs-number">7430</span>张图像的Caption生成<span class="hljs-number">7430</span>个sentence：<br><br></code></pre></td></tr></table></figure>
<p>sentences = dataset_df[class_name].tolist()</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs css"><br>对sentences的处理：首先clean，去掉无关的符号，每个sentence都变为有效单词组成的list，然后通过tokenizer给每个单词编号，tokenizer根据<span class="hljs-selector-tag">Caption</span>生成了<span class="hljs-number">2005</span>个token: &#123;<span class="hljs-string">&#x27;UNK&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;no&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;the&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;is&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;are&#x27;</span>: <span class="hljs-number">5</span>, <span class="hljs-string">&#x27;normal&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;startseq&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;endseq&#x27;</span>: <span class="hljs-number">8</span>, ……………… <span class="hljs-string">&#x27;plateaus&#x27;</span>: <span class="hljs-number">2004</span>, <span class="hljs-string">&#x27;valvuloplasty&#x27;</span>: <span class="hljs-number">2005</span>&#125;：<br></code></pre></td></tr></table></figure>
<pre><code>def init_tokenizer(self, sentences):

    for i in range(len(sentences)):
        if pd.isna(sentences[i]):
            sentences[i] = &quot;&quot;
        sentences[i] = self.clean_sentence(sentences[i])

    # Tokenize the reviews
    print(&quot;Tokenizing dataset..&quot;)
    # Only the most common `num_words-1` words will be kept. 1001-1=1000
    # The number of words to tokinze, the rest will be set as &lt;unk&gt;
    self.tokenizer = Tokenizer(oov_token=&#39;UNK&#39;, num_words=self.tokenizer_num_words)
    self.tokenizer.fit_on_texts(sentences)  # give each word a unique id
    print(&quot;number of tokens: &#123;&#125;&quot;.format(self.tokenizer.word_index))
    print(&quot;Tokenizing is complete.&quot;)
</code></pre>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br>tokenizer完整的初始化部分：<br><br></code></pre></td></tr></table></figure>
<p>class TokenizerWrapper:<br>    def <strong>init</strong>(self, dataset_csv_file, class_name, max_caption_length, tokenizer_num_words=None):<br>        dataset_df = pd.read_csv(dataset_csv_file)  # ‘./IU-XRay/all_data.csv’<br>        sentences = dataset_df[class_name].tolist()  # class_name = ‘Caption’<br>        self.max_caption_length = max_caption_length  # 200<br>        self.tokenizer_num_words = tokenizer_num_words  # 1001<br>        self.init_tokenizer(sentences)<br>        # 预训练的gpt2输出层包含50257个节点，表示英语中的字节对编码(byte-pair encoding)<br>        self.gpt2_tokenizer = GPT2Tokenizer.from_pretrained(‘gpt2’, add_prefix_space=True)<br>        self.gpt2_tokenizer.pad_token = “&lt;”</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br><br>### 准备训练和测试数据<br><br></code></pre></td></tr></table></figure>
<p>train_enqueuer, train_steps = get_enqueuer(FLAGS.train_csv, FLAGS.batch_size, FLAGS, tokenizer_wrapper)<br>test_enqueuer, _ = get_enqueuer(FLAGS.test_csv, 1, FLAGS, tokenizer_wrapper)<br>batch_test_enqueuer, _ = get_enqueuer(FLAGS.test_csv, FLAGS.batch_size, FLAGS, tokenizer_wrapper)<br>train_enqueuer.start(workers=FLAGS.generator_workers, max_queue_size=FLAGS.generator_queue_length)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br>其中部分参数的含义：<br></code></pre></td></tr></table></figure>
<p>self.define(‘generator_queue_length’, 24, ‘The maximum number of batches in the queue to be trained on.’)<br>self.define(‘generator_workers’, 8, ‘The number of cpu workers generating batches.’)</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><br>值得注意的是，在生成数据部分，主要包括<span class="hljs-keyword">self</span>.x_path和<span class="hljs-keyword">self</span>.y：<br></code></pre></td></tr></table></figure>
<p>self.x_path, self.y = df[“Image Index”].values, self.tokenizer_wrapper.GPT2_encode(<br>                df[self.class_names].values<br>                , max_length=1000)</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">self.x_path就是训练数据的名称组成的ndarray，self.y是相应的数据的**caption**通过分词器中的gpt2_tokenizer生成的字节对编码<br><br>### 生成tag embeddings<br></code></pre></td></tr></table></figure>
<p>medical_w2v = Medical_W2V_Wrapper()</p>
<h1 id="medical-w2v-save-embeddings-tokenizer-wrapper-get-word-tokens-list-FLAGS-tags"><a href="#medical-w2v-save-embeddings-tokenizer-wrapper-get-word-tokens-list-FLAGS-tags" class="headerlink" title="medical_w2v.save_embeddings(tokenizer_wrapper.get_word_tokens_list(),FLAGS.tags)"></a>medical_w2v.save_embeddings(tokenizer_wrapper.get_word_tokens_list(),FLAGS.tags)</h1><h1 id="embeddings-medical-w2v-get-embeddings-matrix-for-words-tokenizer-wrapper-get-word-tokens-list"><a href="#embeddings-medical-w2v-get-embeddings-matrix-for-words-tokenizer-wrapper-get-word-tokens-list" class="headerlink" title="embeddings = medical_w2v.get_embeddings_matrix_for_words(tokenizer_wrapper.get_word_tokens_list(),"></a>embeddings = medical_w2v.get_embeddings_matrix_for_words(tokenizer_wrapper.get_word_tokens_list(),</h1><h1 id="FLAGS-tokenizer-vocab-size"><a href="#FLAGS-tokenizer-vocab-size" class="headerlink" title="FLAGS.tokenizer_vocab_size)"></a>FLAGS.tokenizer_vocab_size)</h1><p>tags_embeddings = medical_w2v.get_embeddings_matrix_for_tags(FLAGS.tags)  # ndarray:(105, 400)</p>
<h1 id="print-f”Embeddings-shape-embeddings-shape-”"><a href="#print-f”Embeddings-shape-embeddings-shape-”" class="headerlink" title="print(f”Embeddings shape: {embeddings.shape}”)"></a>print(f”Embeddings shape: {embeddings.shape}”)</h1><p>print(f”Tags Embeddings shape: {tags_embeddings.shape}”)<br>del medical_w2v</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>### 编码器<br></code></pre></td></tr></table></figure>
<p>encoder = CNN_Encoder(‘pretrained_visual_model’,<br>                      FLAGS.visual_model_name,   # ‘fine_tuned_chexnet’<br>                      FLAGS.visual_model_pop_layers,  # 2<br>                      FLAGS.encoder_layers,   # 0.4<br>                      FLAGS.tags_threshold,   # -1<br>                      tags_embeddings,<br>                      FLAGS.finetune_visual_model)  # False</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br>导入预训练模型：<br><br></code></pre></td></tr></table></figure>
<p>def load_model(load_path, model_name):<br>    path = os.path.join(load_path, model_name)</p>
<pre><code># load json and create model
json_file = open(&#39;&#123;&#125;.json&#39;.format(path), &#39;r&#39;)
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# # load weights into new model
loaded_model.load_weights(&quot;&#123;&#125;.h5&quot;.format(path))
print(&quot;Loaded model from disk&quot;)
return loaded_model
</code></pre>
<figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs fortran"><br>模型有<span class="hljs-number">429</span>个layer，其中最后两层：<br>* <span class="hljs-number">427</span>： GlobalAveragePooling2D，input <span class="hljs-built_in">shape</span>：(<span class="hljs-keyword">None</span>,<span class="hljs-number">7</span>,<span class="hljs-number">7</span>,<span class="hljs-number">1024</span>) output <span class="hljs-built_in">shape</span>:(<span class="hljs-keyword">None</span>,<span class="hljs-number">1024</span>)<br>* <span class="hljs-number">428</span>： **Flatten+Dense**input <span class="hljs-built_in">shape</span>：(<span class="hljs-keyword">None</span>,<span class="hljs-number">1024</span>) output <span class="hljs-built_in">shape</span>:(<span class="hljs-keyword">None</span>,<span class="hljs-number">105</span>)<br><br>### 解码器<br><br>解码器是预训练的GPT2模型：<br><br></code></pre></td></tr></table></figure>
<p>decoder = TFGPT2LMHeadModel.from_pretrained(‘distilgpt2’, from_pt=True, resume_download=True)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br>解码器的三个输入：<br></code></pre></td></tr></table></figure>
<h1 id="passing-the-features-through-the-decoder"><a href="#passing-the-features-through-the-decoder" class="headerlink" title="passing the features through the decoder"></a>passing the features through the decoder</h1><p>predictions, _ = decoder(dec_input, visual_features=visual_features, tags_embeddings=tags_embeddings, past=None)</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>#### GPT2config<br></code></pre></td></tr></table></figure>
<p>GPT2Config {<br>  “<em>num_labels”: 1,<br>  “activation_function”: “gelu_new”,<br>  “architectures”: [<br>    “GPT2LMHeadModel”<br>  ],<br>  “attn_pdrop”: 0.1,<br>  “bos_token_id”: 50256,<br>  “do_sample”: false,<br>  “embd_pdrop”: 0.1,<br>  “eos_token_id”: 50256,<br>  “eos_token_ids”: 0,<br>  “finetuning_task”: null,<br>  “id2label”: {<br>    “0”: “LABEL_0”<br>  },<br>  “initializer_range”: 0.02,<br>  “is_decoder”: false,<br>  “label2id”: {<br>    “LABEL_0”: 0<br>  },<br>  “layer_norm_epsilon”: 1e-05,<br>  “length_penalty”: 1.0,<br>  “max_length”: 20,<br>  “model_type”: “gpt2”,<br>  “n_ctx”: 1024,<br>  “n_embd”: 768,<br>  “n_head”: 12,<br>  “n_layer”: 6,<br>  “n_positions”: 1024,<br>  “num_beams”: 1,<br>  “num_labels”: 2,<br>  “num_return_sequences”: 1,<br>  “output_attentions”: false,<br>  “output_hidden_states”: false,<br>  “output_past”: true,<br>  “pad_token_id”: 0,<br>  “pruned_heads”: {},<br>  “repetition_penalty”: 1.0,<br>  “resid_pdrop”: 0.1,<br>  “summary_activation”: null,<br>  “summary_first_dropout”: 0.1,<br>  “summary_proj_to_labels”: true,<br>  “summary_type”: “cls_index”,<br>  “summary_use_proj”: true,<br>  “task_specific_params”: {<br>    “text-generation”: {<br>      “do_sample”: true,<br>      “max_length”: 50<br>    }<br>  },<br>  “temperature”: 1.0,<br>  “top_k”: 50,<br>  “top_p”: 1.0,<br>  “torchscript”: false,<br>  “use_bfloat16”: false,<br>  “vocab_size”: 50257<br>}<br>self.h = [TFBlock(config.n_ctx, config, scale=True, name=”h</em>._{}”.format(i)) for i in range(config.n_layer)]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs plain">代码实现主要包含四个部分：<br><br></code></pre></td></tr></table></figure>
<p>class TFAttention(tf.keras.layers.Layer):…<br>class TFBlock(tf.keras.layers.Layer):…<br>class TFGPT2MainLayer(tf.keras.layers.Layer):…<br>class TFGPT2LMHeadModel(TFGPT2PreTrainedModel):…</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>#### TFAttention<br><br>#### TFGPT2MainLayer<br></code></pre></td></tr></table></figure>
<p>input_ids = inputs  # (1, 999)<br>past = [None] * len(self.h)  # [None,None,None,None,None,None]<br>position_ids = tf.range(past_length, input_shape[-1] + past_length, dtype=tf.int32)[tf.newaxis, :]  # [[0, 1, 2, …, 998]]<br>attention_mask = None<br>head_mask = [None] * self.num_hidden_layers  # 6<br>inputs_embeds = self.wte(input_ids, mode=”embedding”)  # [1,999,768]<br>position_embeds = self.wpe(position_ids)  # [1,999,768]<br>token_type_embeds = 0<br>hidden_states = inputs_embeds + position_embeds + token_type_embeds<br>hidden_states = self.drop(hidden_states, training=training)<br>output_shape = input_shape + [shape_list(hidden_states)[-1]]  # [1,999,768]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plain"><br></code></pre></td></tr></table></figure>
<p>for i, (block, layer_past) in enumerate(zip(self.h, past)):<br>            outputs = block([hidden_states, layer_past, attention_mask, head_mask[i], visual_features, tags_embeddings],<br>                            training=training)<br>            hidden_states, present = outputs[:2]  # (1,999,768)  (1,2,12,1153,64)</p>
<p>hidden_states = self.ln_f(hidden_states  # (1,999,768)</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">#### TFGPT2LMHeadModel<br></code></pre></td></tr></table></figure>
<pre><code>    transformer_outputs = self.transformer(inputs, visual_features, tags_embeddings, **kwargs)  # (batchsize, 999)  (batchsize, 49, 1024)  (batchsize, 105, 400)
    hidden_states = transformer_outputs[0]  # (1,999,768)
    lm_logits = self.transformer.wte(hidden_states, mode=&quot;linear&quot;)  # (1, 999, 50257)
    outputs = (lm_logits,) + transformer_outputs[1:]  # (1, 999, 50257) + (1,2,12,1153,64)
</code></pre>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>#### GPT2实现部分的理解<br>* 在训练部分传入参数：<br><br></code></pre></td></tr></table></figure>
<p>predictions, _ = decoder(dec_input, visual_features=visual_features, tags_embeddings=tags_embeddings, past=None)</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-bullet">* </span>调用预训练GPT2：<br><br></code></pre></td></tr></table></figure>
<p>self.transformer = TFGPT2MainLayer(config, name=”transformer”)</p>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><br><span class="hljs-bullet">* </span>transformer首先将输入转换为词嵌入((1,999)to(1,999,768))<br><br><span class="hljs-bullet">* </span>输入自注意力网络：<br></code></pre></td></tr></table></figure>
<pre><code>        outputs = block([hidden_states, layer_past, attention_mask, head_mask[i], visual_features, tags_embeddings],
                        training=training)
</code></pre>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><br><span class="hljs-bullet">*</span> 自注意力的实现：<br><span class="hljs-bullet">  *</span> 初始化qkv<br>  <br></code></pre></td></tr></table></figure>
<pre><code>      x = self.c_attn(x)

    query, key, value = tf.split(x, 3, axis=2)

    query = self.split_heads(query)
    key = self.split_heads(key)
    value = self.split_heads(value)
</code></pre>
  <figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><br>* 把tags和<span class="hljs-built_in">values</span>拼到<span class="hljs-built_in">key</span>和value上：<br><br></code></pre></td></tr></table></figure>
<pre><code>          key, value = self.concat_features(key,value,visual_features,self.visual_attn)
        key, value = self.concat_features(key,value,tags_embeddings,self.tags_attn)
</code></pre>
  <figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><br><span class="hljs-bullet">* </span>计算注意力输出：<br><br></code></pre></td></tr></table></figure>
<p>  attn_outputs = self._attn([query, key, value, attention_mask, head_mask], training=training)<br>  <figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><br><span class="hljs-bullet">* </span>将生成的词嵌入与wte相乘：<br></code></pre></td></tr></table></figure><br>        lm_logits = self.transformer.wte(hidden_states, mode=”linear”)</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs clean">(<span class="hljs-number">1</span>,<span class="hljs-number">999</span>,<span class="hljs-number">768</span>) to (<span class="hljs-number">1</span>,<span class="hljs-number">999</span>,<span class="hljs-number">50257</span>),也就是说生成了每个位置关于每个单词的注意力得分<br><br>### 训练部分<br></code></pre></td></tr></table></figure>
<p>@tf.function<br>def train_step(images, target, test_mode=False):<br>    with tf.GradientTape() as tape:<br>        visual_features, tags_embeddings = encoder(images)  # (batchsize, 49, 1024)  (batchsize, 105, 400)<br>        dec_input = target[:, 0:-1]</p>
<pre><code>    # passing the features through the decoder
    predictions, _ = decoder(dec_input, visual_features=visual_features, tags_embeddings=tags_embeddings, past=None)

    loss = loss_function(target[:, 1:], predictions)
if not test_mode:
    trainable_variables = encoder.trainable_variables + decoder.trainable_variables
    gradients = tape.gradient(loss, trainable_variables)
    optimizer.apply_gradients(zip(gradients, trainable_variables))
return loss
</code></pre>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><br><span class="hljs-bullet">* </span>输入的images和target由generator生成：<br></code></pre></td></tr></table></figure>
<p>img, target, _ = next(train_generator)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plain">其中的数据准备部分：<br></code></pre></td></tr></table></figure>
<pre><code>def prepare_dataset(self):
    df = self.dataset_df.sample(frac=1., random_state=self.random_state)
    if self.augmenter is not None:
        self.x_path, self.y = df[&quot;Image Index&quot;].values, self.tokenizer_wrapper.GPT2_encode(
            df[self.class_names].values)
    else:
        self.x_path, self.y = df[&quot;Image Index&quot;].values, self.tokenizer_wrapper.GPT2_encode(
            df[self.class_names].values
            , max_length=1000)
</code></pre>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">x</span>.path保存图片名称，y保存通过GPT<span class="hljs-number">2</span>将caption转化为的词向量，通过getitem按批大小导入：<br></code></pre></td></tr></table></figure>
<pre><code>def __getitem__(self, idx):
    batch_x_path = self.x_path[idx * self.batch_size:(idx + 1) * self.batch_size]
    batch_x = np.asarray([self.load_image(x_path) for x_path in batch_x_path])
    batch_x = self.transform_batch_images(batch_x)
    batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
    return batch_x, batch_y, batch_x_path
</code></pre>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><span class="hljs-bullet">* </span>通过编码器获得视觉特征和加权词嵌入<br></code></pre></td></tr></table></figure>
<pre><code>    visual_features, tags_embeddings = encoder(images)  # (batchsize, 49, 1024)  (batchsize, 105, 400)
</code></pre>
<figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc"><br><span class="hljs-bullet">* </span>通过解码器获得网络预测<br></code></pre></td></tr></table></figure>
<h1 id="passing-the-features-through-the-decoder-1"><a href="#passing-the-features-through-the-decoder-1" class="headerlink" title="passing the features through the decoder"></a>passing the features through the decoder</h1><pre><code>    predictions, _ = decoder(dec_input, visual_features=visual_features, tags_embeddings=tags_embeddings, past=None)  # （1,999,50257）
</code></pre>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs clean"><br>### 损失函数<br></code></pre></td></tr></table></figure>
<p>def loss_function(real, pred):  # (1,999) (1,999,50257)<br>    mask = tf.math.logical_not(tf.math.equal(real, tokenizer_wrapper.GPT2_pad_token_id()))  # (1,999)<br>    loss_ = loss_object(real, pred)  # (1,999)</p>
<pre><code>mask = tf.cast(mask, dtype=loss_.dtype)
loss_ *= mask

return tf.reduce_mean(loss_)  # 均值
</code></pre>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs plain">其中：<br></code></pre></td></tr></table></figure>
<p>loss_object = tf.keras.losses.SparseCategoricalCrossentropy(<br>    from_logits=True, reduction=’none’)</p>
<p>```</p>
<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><ul>
<li>keras tokenizer作用是什么？</li>
<li>self.wte是否需要训练，具体实现的原理？（好像是需要训练的）</li>
<li>网络中的Feed Forward部分是什么结构？</li>
<li>qkv具体是什么</li>
<li>预训练GPT2体现在哪里</li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/CDGPT2/">CDGPT2</a>
                    
                      <a class="hover-with-bg" href="/tags/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">论文笔记</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    个人学习记录所用
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/09/03/%E6%AF%8F%E5%91%A8%E4%BB%A3%E7%A0%81-8-28-9-3/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">每周代码(8.28-9.3)</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/08/27/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">
                        <span class="hidden-mobile">论文笔记</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.2/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      $('#local-search-input').on('click', function() {
        searchFunc(path, 'local-search-input', 'local-search-result');
      });
      $('#modalSearch').on('shown.bs.modal', function() {
        $('#local-search-input').focus();
      });
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
