

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
  <title>MNIST手写数字识别 - Hexo</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.6.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"joexy312.github.io","root":"/","version":"1.8.10","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 20vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Joe</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="MNIST手写数字识别">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-07-23 11:41" pubdate>
        2021年7月23日 中午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      1.1k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      19
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">MNIST手写数字识别</h1>
            
            <div class="markdown-body">
              <h2 id="模型设计"><a href="#模型设计" class="headerlink" title="模型设计"></a>模型设计</h2><p>首先手写了一个简单的CNN：</p>
<figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-class"><span class="hljs-keyword">class</span> network(<span class="hljs-title">nn</span>.<span class="hljs-type">Module</span>):</span><br><span class="hljs-class">    def __init__(<span class="hljs-title">self</span>):</span><br><span class="hljs-class">        super(<span class="hljs-title">network</span>, <span class="hljs-title">self</span>).__init__()</span><br><span class="hljs-class">        self.net = nn.<span class="hljs-type">Sequential</span>(</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Conv2d</span>(1, 32, <span class="hljs-title">kernel_size</span>=3, <span class="hljs-title">stride</span>=1, <span class="hljs-title">padding</span>=1, <span class="hljs-title">bias</span>=<span class="hljs-type">False</span>),</span><br><span class="hljs-class">            nn.<span class="hljs-type">BatchNorm2d</span>(32),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>(),</span><br><span class="hljs-class">            nn.<span class="hljs-type">Conv2d</span>(32, 64, <span class="hljs-title">kernel_size</span>=3, <span class="hljs-title">stride</span>=1, <span class="hljs-title">padding</span>=1, <span class="hljs-title">bias</span>=<span class="hljs-type">False</span>),</span><br><span class="hljs-class">            nn.<span class="hljs-type">BatchNorm2d</span>(64),</span><br><span class="hljs-class">            nn.<span class="hljs-type">ReLU</span>()</span><br><span class="hljs-class">        )</span><br><span class="hljs-class">        self.classifier = nn.<span class="hljs-type">Sequential</span>(</span><br><span class="hljs-class">            <span class="hljs-title">nn</span>.<span class="hljs-type">Linear</span>(50176, 10)</span><br><span class="hljs-class">        )</span><br><span class="hljs-class"></span><br><span class="hljs-class">    def forward(<span class="hljs-title">self</span>, <span class="hljs-title">data</span>):</span><br><span class="hljs-class">        x = self.net(<span class="hljs-title">data</span>)</span><br><span class="hljs-class">        # x = <span class="hljs-type">F</span>.adaptive_avg_pool2d(<span class="hljs-title">x</span>, (1, 1))</span><br><span class="hljs-class">        x = torch.flatten(<span class="hljs-title">x</span>, 1)</span><br><span class="hljs-class">        x = self.classifier(<span class="hljs-title">x</span>)</span><br><span class="hljs-class">        return <span class="hljs-type">F</span>.log_softmax(<span class="hljs-title">x</span>)</span><br></code></pre></td></tr></table></figure>
<p>网络由两个卷积层组成，每个卷积层后接BN和ReLU函数，将提取到的特征通过flatten函数铺平后输入全连接层进行分类，然后通过softmax函数输出分类结果。</p>
<p>复现了一下vgg网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_layers</span>(<span class="hljs-params">cfg, batch_norm=<span class="hljs-literal">False</span></span>):</span><br>    layers = []<br>    in_channels = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> cfg:<br>        <span class="hljs-keyword">if</span> v == <span class="hljs-string">&#x27;M&#x27;</span>:<br>            layers += [nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)]<br>        <span class="hljs-keyword">else</span>:<br>            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">if</span> batch_norm:<br>                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="hljs-literal">True</span>)]<br>            <span class="hljs-keyword">else</span>:<br>                layers += [conv2d, nn.ReLU(inplace=<span class="hljs-literal">True</span>)]<br>            in_channels = v<br>    <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">vgg</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(vgg, self).__init__()<br>        self.net_arch = [<span class="hljs-number">64</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">128</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;M&#x27;</span>]<br>        <span class="hljs-comment"># self.net_arch = [64, &#x27;M&#x27;, 128, &#x27;M&#x27;, 256, 256, &#x27;M&#x27;, 512, 512, &#x27;M&#x27;, 512, 512, &#x27;M&#x27;]</span><br>        self.features = make_layers(self.net_arch, <span class="hljs-literal">False</span>)<br>        self.avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        self.classifier = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>),<br>            nn.ReLU(<span class="hljs-literal">True</span>),<br>            nn.Dropout(),<br>            nn.Linear(<span class="hljs-number">256</span>, <span class="hljs-number">10</span>),<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, data</span>):</span><br>        x = self.features(data)<br>        x = self.avgpool(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.classifier(x)<br>        <span class="hljs-keyword">return</span> F.log_softmax(x)<br></code></pre></td></tr></table></figure>
<p>网络结构部分，因为使用原始的vgg网络参数太多，会过拟合，所以去掉了一部分卷积层</p>
<figure class="highlight gml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gml"><span class="hljs-literal">self</span>.net_arch = [<span class="hljs-number">64</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">128</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;M&#x27;</span>]<br># <span class="hljs-literal">self</span>.net_arch = [<span class="hljs-number">64</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">128</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">512</span>, <span class="hljs-number">512</span>, <span class="hljs-string">&#x27;M&#x27;</span>, <span class="hljs-number">512</span>, <span class="hljs-number">512</span>, <span class="hljs-string">&#x27;M&#x27;</span>]<br></code></pre></td></tr></table></figure>

<p>之前在周三的组会听了一下RepVGG的设计，自己也去学习了一下，这里再比较了一下Repvgg的效果。RepVGG主要的设计思路就是在测试的时候去掉多分支结构，提升网络的效率。方法就是把3x3conv， 1x1conv， identity， BN 全部合并成3x3卷积，同时由于VGG网络采用3x3的卷积核，计算效率也很高。</p>
<p>其中1x1和3x3的合并：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">def</span> _pad_<span class="hljs-number">1</span>x<span class="hljs-number">1</span>_to_<span class="hljs-number">3</span>x<span class="hljs-number">3</span>_tensor(self, kernel<span class="hljs-number">1</span>x<span class="hljs-number">1</span>):<br>    <span class="hljs-attribute">if</span> kernel<span class="hljs-number">1</span>x<span class="hljs-number">1</span> is None:<br>        <span class="hljs-attribute">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-attribute">else</span>:<br>        <span class="hljs-attribute">return</span> torch.nn.functional.pad(kernel<span class="hljs-number">1</span>x<span class="hljs-number">1</span>,<span class="hljs-meta"> [1,1,1,1])</span><br></code></pre></td></tr></table></figure>
<p>BN和conv的合并：</p>
<figure class="highlight nix"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs nix">def _fuse_bn_tensor(self, branch):<br>    <span class="hljs-keyword">if</span> branch is None:<br>        return <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span> isinstance(branch, nn.Sequential):<br>        <span class="hljs-attr">kernel</span> = branch.conv.weight<br>        <span class="hljs-attr">running_mean</span> = branch.bn.running_mean<br>        <span class="hljs-attr">running_var</span> = branch.bn.running_var<br>        <span class="hljs-attr">gamma</span> = branch.bn.weight<br>        <span class="hljs-attr">beta</span> = branch.bn.bias<br>        <span class="hljs-attr">eps</span> = branch.bn.eps<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">assert</span> isinstance(branch, nn.BatchNorm2d)<br>        <span class="hljs-keyword">if</span> not hasattr(self, &#x27;id_tensor&#x27;):<br>            <span class="hljs-attr">input_dim</span> = self.in_channels // self.groups<br>            <span class="hljs-attr">kernel_value</span> = np.zeros((self.in_channels, input_dim, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>), <span class="hljs-attr">dtype=np.float32)</span><br>            for i <span class="hljs-keyword">in</span> range(self.in_channels):<br>                kernel_value[i, i % input_dim, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>] = <span class="hljs-number">1</span><br>            self.<span class="hljs-attr">id_tensor</span> = torch.from_numpy(kernel_value).to(branch.weight.device)<br>        <span class="hljs-attr">kernel</span> = self.id_tensor<br>        <span class="hljs-attr">running_mean</span> = branch.running_mean<br>        <span class="hljs-attr">running_var</span> = branch.running_var<br>        <span class="hljs-attr">gamma</span> = branch.weight<br>        <span class="hljs-attr">beta</span> = branch.bias<br>        <span class="hljs-attr">eps</span> = branch.eps<br>    <span class="hljs-attr">std</span> = (running_var + eps).sqrt()<br>    <span class="hljs-attr">t</span> = (gamma / std).reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>    return kernel * t, beta - running_mean * gamma / std<br></code></pre></td></tr></table></figure>

<p>全部合并成3x3卷积：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">def</span> get_equivalent_kernel_bias(self):<br>    <span class="hljs-attribute">kernel3x3</span>, bias<span class="hljs-number">3</span>x<span class="hljs-number">3</span> = self._fuse_bn_tensor(self.rbr_dense)<br>    <span class="hljs-attribute">kernel1x1</span>, bias<span class="hljs-number">1</span>x<span class="hljs-number">1</span> = self._fuse_bn_tensor(self.rbr_<span class="hljs-number">1</span>x<span class="hljs-number">1</span>)<br>    <span class="hljs-attribute">kernelid</span>, biasid = self._fuse_bn_tensor(self.rbr_identity)<br>    <span class="hljs-attribute">return</span> kernel<span class="hljs-number">3</span>x<span class="hljs-number">3</span> + self._pad_<span class="hljs-number">1</span>x<span class="hljs-number">1</span>_to_<span class="hljs-number">3</span>x<span class="hljs-number">3</span>_tensor(kernel<span class="hljs-number">1</span>x<span class="hljs-number">1</span>) + kernelid, bias<span class="hljs-number">3</span>x<span class="hljs-number">3</span> + bias<span class="hljs-number">1</span>x<span class="hljs-number">1</span> + biasid<br></code></pre></td></tr></table></figure>

<h2 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h2><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">def parse<span class="hljs-constructor">_opts()</span>:<br><br>    parser = argparse.<span class="hljs-constructor">ArgumentParser(<span class="hljs-params">description</span>=<span class="hljs-string">&quot;MNIST&quot;</span>)</span><br>    parser.add<span class="hljs-constructor">_argument(&#x27;--<span class="hljs-params">batch_size</span>&#x27;, <span class="hljs-params">default</span>=32, <span class="hljs-params">type</span>=<span class="hljs-params">int</span>, <span class="hljs-params">help</span>=&#x27;<span class="hljs-params">the</span> <span class="hljs-params">batch</span> <span class="hljs-params">size</span> <span class="hljs-params">set</span> <span class="hljs-params">for</span> <span class="hljs-params">the</span> <span class="hljs-params">network</span>&#x27;)</span><br>    parser.add<span class="hljs-constructor">_argument(&#x27;--<span class="hljs-params">epoch</span>&#x27;, <span class="hljs-params">default</span>=100, <span class="hljs-params">type</span>=<span class="hljs-params">int</span>, <span class="hljs-params">help</span>=&#x27;<span class="hljs-params">the</span> <span class="hljs-params">epoch</span> <span class="hljs-params">number</span> <span class="hljs-params">set</span> <span class="hljs-params">for</span> <span class="hljs-params">the</span> <span class="hljs-params">network</span>&#x27;)</span><br>    parser.add<span class="hljs-constructor">_argument(&#x27;--<span class="hljs-params">lr</span>&#x27;, <span class="hljs-params">default</span>=3e-4, <span class="hljs-params">type</span>=<span class="hljs-params">float</span>, <span class="hljs-params">help</span>=&#x27;<span class="hljs-params">the</span> <span class="hljs-params">learning</span> <span class="hljs-params">rate</span> <span class="hljs-params">of</span> <span class="hljs-params">the</span> <span class="hljs-params">optimizer</span>&#x27;)</span><br>    args = parser.parse<span class="hljs-constructor">_args()</span><br>    return args<br></code></pre></td></tr></table></figure>

<h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>该函数从torchvision。datasets中的MNIST数据集下载数据，并进行标准化。然后对数据进行reshape，增加通道这一列。然后返回TensorDataset用于后续处理。</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs routeros">def data_loader():<br>    dataset = datasets.MNIST(<span class="hljs-string">&#x27;./data&#x27;</span>,<br>                             <span class="hljs-attribute">train</span>=<span class="hljs-literal">True</span>,<br>                             <span class="hljs-attribute">transform</span>=transforms.ToTensor(),<br>                             <span class="hljs-attribute">target_transform</span>=transforms.Normalize((0.1307,), (0.3081,)),<br>                             <span class="hljs-attribute">download</span>=<span class="hljs-literal">True</span>)<br>    train_x = torch.reshape(dataset.train_data, (-1, 1, 28, 28))<br>    <span class="hljs-builtin-name">print</span>(train_x[0][0])<br>    train_y = dataset.train_labels<br>    test_x = torch.reshape(dataset.test_data, (-1, 1, 28, 28))<br>    test_y = dataset.test_labels<br><br>    <span class="hljs-builtin-name">print</span>(f<span class="hljs-string">&#x27;train_x:&#123;train_x.shape&#125;,train_y:&#123;train_y&#125;,test_x:&#123;test_x&#125;,test_y:&#123;test_y&#125;&#x27;</span>)<br>    train_set = TensorDataset(train_x, train_y)<br>    test_set = TensorDataset(test_x, test_y)<br><br>    return train_set, test_set<br></code></pre></td></tr></table></figure>

<h2 id="读取数据"><a href="#读取数据" class="headerlink" title="读取数据"></a>读取数据</h2><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">batchsize = parse<span class="hljs-constructor">_opts()</span>.batch_size<br>epoch = parse<span class="hljs-constructor">_opts()</span>.epoch<br>lr = parse<span class="hljs-constructor">_opts()</span>.lr<br><br>train_set, test_set = data<span class="hljs-constructor">_loader()</span><br>train_set = <span class="hljs-constructor">DataLoader(<span class="hljs-params">train_set</span>, <span class="hljs-params">batchsize</span>, <span class="hljs-params">shuffle</span>=True)</span><br>test_set = <span class="hljs-constructor">DataLoader(<span class="hljs-params">test_set</span>, <span class="hljs-params">batchsize</span>, <span class="hljs-params">shuffle</span>=False)</span><br>device = &#x27;cuda:<span class="hljs-number">0</span>&#x27;<br></code></pre></td></tr></table></figure>

<h2 id="读取模型"><a href="#读取模型" class="headerlink" title="读取模型"></a>读取模型</h2><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">model1</span> = network().cuda()<br><span class="hljs-comment"># model2 = vgg().cuda()</span><br><span class="hljs-comment"># model3 = create_RepVGG_A0().cuda()</span><br></code></pre></td></tr></table></figure>

<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs css">for <span class="hljs-selector-tag">i</span> in range(epoch):<br>    train_losses = []<br>    start_time = time.<span class="hljs-built_in">time</span>()<br>    model.<span class="hljs-built_in">train</span>()<br>    correct = <span class="hljs-number">0</span><br>    image_num = <span class="hljs-built_in">len</span>(test_set) * batchsize<br>    for data, target in train_set:<br>        data = data.<span class="hljs-built_in">float</span>().<span class="hljs-built_in">cuda</span>(device)<br>        target = target.<span class="hljs-built_in">cuda</span>(device)<br>        optimizer = <span class="hljs-built_in">Adam</span>(<span class="hljs-built_in">filter</span>(lambda p: p.requires_grad, model.<span class="hljs-built_in">parameters</span>()), lr=lr)<br>        optimizer.<span class="hljs-built_in">zero_grad</span>()<br>        output = <span class="hljs-built_in">model</span>(data)<br>        trn_loss = F.<span class="hljs-built_in">nll_loss</span>(output, target)<br>        train_losses.<span class="hljs-built_in">append</span>(trn_loss.<span class="hljs-built_in">item</span>())<br>        trn_loss.<span class="hljs-built_in">backward</span>()<br>        optimizer.<span class="hljs-built_in">step</span>()<br><br>        pred = output.data.<span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, keepdim=True)[<span class="hljs-number">1</span>]<br>        correct += pred.<span class="hljs-built_in">eq</span>(target.data.<span class="hljs-built_in">view_as</span>(pred)).<span class="hljs-built_in">sum</span>()<br><br>    trn_losses = np.<span class="hljs-built_in">sum</span>(train_losses) / <span class="hljs-built_in">len</span>(train_losses)<br>    <span class="hljs-built_in">print</span>(f<span class="hljs-string">&#x27;epoch &#123;i+1&#125;: loss: &#123;trn_losses&#125;, acc: &#123;correct.cpu().numpy()/image_num&#125;&#x27;</span>)<br></code></pre></td></tr></table></figure>

<h2 id="模型验证"><a href="#模型验证" class="headerlink" title="模型验证"></a>模型验证</h2><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-title">model</span>.eval()<br><span class="hljs-title">test_losses</span> = []<br><span class="hljs-title">correct</span> = <span class="hljs-number">0</span><br><span class="hljs-title">image_num</span> = len(test_set) * batchsize<br><span class="hljs-title">for</span> batch_idx, (<span class="hljs-class"><span class="hljs-keyword">data</span>, target) in enumerate(<span class="hljs-title">test_set</span>):</span><br>    with torch.no_grad():<br>        <span class="hljs-class"><span class="hljs-keyword">data</span> = <span class="hljs-keyword">data</span>.float().cuda(<span class="hljs-title">device</span>)</span><br>        target = target.cuda(device)<br>        output = model(<span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br>        loss = <span class="hljs-type">F</span>.nll_loss(output, target)<br>        test_losses.append(loss.item())<br>        pred = output.<span class="hljs-class"><span class="hljs-keyword">data</span>.max(1, <span class="hljs-title">keepdim</span>=<span class="hljs-type">True</span>)[1]</span><br>        correct += pred.eq(target.<span class="hljs-class"><span class="hljs-keyword">data</span>.view_as(<span class="hljs-title">pred</span>)).sum()</span><br><span class="hljs-title">print</span>(f&#x27;final test acc: &#123;correct.cpu().numpy()/image_num&#125;&#x27;)<br><br></code></pre></td></tr></table></figure>

<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p><img src="/img/mnist.png" srcset="/img/loading.gif" lazyload alt="RepVGG"></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
              </div>
              
                <p class="note note-warning">
                  
                    个人学习记录所用
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/07/22/%E6%AF%8F%E5%91%A8%E4%BB%A3%E7%A0%81-7-17-7-23/">
                        <span class="hidden-mobile">每周代码(7.17-7.23)</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.2/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/local-search.xml";
      $('#local-search-input').on('click', function() {
        searchFunc(path, 'local-search-input', 'local-search-result');
      });
      $('#modalSearch').on('shown.bs.modal', function() {
        $('#local-search-input').focus();
      });
    })()
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
