<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>深度学习代码编写基本模板(Pytorch) | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="使用Pytorch编写深度学习代码的基本框架供自己以后使用，并在不断优化中。 experiments.py导入包： 12345678from main import *from torch.optim import lr_schedulerfrom torch.optim.adam import Adamimport torch.nn as nnfrom models.model import n">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习代码编写基本模板(Pytorch)">
<meta property="og:url" content="http://example.com/2021/03/10/%E6%A8%A1%E6%9D%BF/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="使用Pytorch编写深度学习代码的基本框架供自己以后使用，并在不断优化中。 experiments.py导入包： 12345678from main import *from torch.optim import lr_schedulerfrom torch.optim.adam import Adamimport torch.nn as nnfrom models.model import n">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-03-10T07:35:39.716Z">
<meta property="article:modified_time" content="2021-03-10T07:35:39.720Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-模板" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/03/10/%E6%A8%A1%E6%9D%BF/" class="article-date">
  <time class="dt-published" datetime="2021-03-10T07:35:39.716Z" itemprop="datePublished">2021-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      深度学习代码编写基本模板(Pytorch)
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>使用Pytorch编写深度学习代码的基本框架供自己以后使用，并在不断优化中。</p>
<h2 id="experiments-py"><a href="#experiments-py" class="headerlink" title="experiments.py"></a>experiments.py</h2><p>导入包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">from main import *</span><br><span class="line">from torch.optim import lr_scheduler</span><br><span class="line">from torch.optim.adam import Adam</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from models.model import network</span><br><span class="line"># 调试工具</span><br><span class="line">import torchsnooper</span><br><span class="line">import optuna</span><br></pre></td></tr></table></figure>

<p>主函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    # 设置随机种子</span><br><span class="line">    reset_rand()</span><br><span class="line">    </span><br><span class="line">    # 目标函数，返回acc供optuna自动优化</span><br><span class="line">    def objective(trial):</span><br><span class="line">        def model_opt():</span><br><span class="line">            lr &#x3D; trial.suggest_discrete_uniform(&#39;lr&#39;, 1e-3, 1e-2, 1e-3)</span><br><span class="line">            model &#x3D; network()</span><br><span class="line">            optimizer &#x3D; Adam(model.parameters(), lr)</span><br><span class="line">            # scheduler &#x3D; lr_scheduler.MultiStepLR(optimizer&#x3D;optimizer, milestones&#x3D;[10], gamma&#x3D;0.1)</span><br><span class="line">            scheduler &#x3D; None</span><br><span class="line">            return model, optimizer, scheduler</span><br><span class="line"></span><br><span class="line">        acc &#x3D; kFoldTraining(wd,</span><br><span class="line">                            int(trial.suggest_discrete_uniform(&#39;batch_size&#39;, 32, 256, 32)),</span><br><span class="line">                            epoch,</span><br><span class="line">                            model_optimizer&#x3D;model_opt,</span><br><span class="line">                            loss&#x3D;nn.CrossEntropyLoss(),</span><br><span class="line">                            device&#x3D;&#39;cuda:0&#39;,</span><br><span class="line">                            deterministic&#x3D;True,</span><br><span class="line">                            parallel&#x3D;False</span><br><span class="line">                            )</span><br><span class="line">        return acc</span><br><span class="line">    </span><br><span class="line">    # 保存自动调参数结果</span><br><span class="line">    study &#x3D; optuna.create_study(direction&#x3D;&quot;maximize&quot;, pruner&#x3D;optuna.pruners.HyperbandPruner())</span><br><span class="line">    study.optimize(objective, n_trials&#x3D;50)</span><br><span class="line">    print(&quot;Number of finished trials: &quot;, len(study.trials))</span><br><span class="line">    print(&quot;Best trial:&quot;)</span><br><span class="line">    trial &#x3D; study.best_trial</span><br><span class="line">    print(&quot;  Value: &quot;, trial.value)</span><br><span class="line">    print(&quot;  Params: &quot;)</span><br><span class="line">    for key, value in trial.params.items():</span><br><span class="line">        print(&quot;    &#123;&#125;: &#123;&#125;&quot;.format(key, value))</span><br><span class="line"></span><br><span class="line">    df &#x3D; study.trials_dataframe(attrs&#x3D;(&#39;number&#39;, &#39;value&#39;, &#39;params&#39;, &#39;state&#39;))</span><br><span class="line">    df.to_csv(wd+ &#39;&#x2F;dataframe.csv&#39;, index&#x3D;False)</span><br></pre></td></tr></table></figure>

<h2 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h2><p>导入包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from utils.utils import *</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from trainer import trainer</span><br><span class="line">import torchsnooper</span><br></pre></td></tr></table></figure>
<p>主函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">#@torchsnooper.snoop()</span><br><span class="line">def kFoldTraining(data_path,</span><br><span class="line">                  batch_size&#x3D;32,</span><br><span class="line">                  n_epochs&#x3D;50,</span><br><span class="line">                  model_optimizer&#x3D;None,</span><br><span class="line">                  loss&#x3D;None,</span><br><span class="line">                  device&#x3D;&#39;cuda:0&#39;,</span><br><span class="line">                  deterministic&#x3D;False,</span><br><span class="line">                  parallel&#x3D;False):</span><br><span class="line">    for fold in range(1):</span><br><span class="line">        reset_rand()</span><br><span class="line">        tr_set, test_set &#x3D; getDataset(data_path + &#39;&#x2F;label.csv&#39;, fold)</span><br><span class="line">        tr_set &#x3D; DataLoader(tr_set, batch_size, shuffle&#x3D;True)</span><br><span class="line">        test_set &#x3D; DataLoader(test_set, batch_size, shuffle&#x3D;False)</span><br><span class="line"></span><br><span class="line">        model, optimizer, scheduler &#x3D; model_optimizer()</span><br><span class="line">        tr &#x3D; trainer(tr_set, test_set, batch_size, n_epochs, model, optimizer, scheduler, loss, device,</span><br><span class="line">                     deterministic, parallel)</span><br><span class="line">        acc &#x3D; tr.run(fold)</span><br><span class="line">        del tr</span><br><span class="line">    return acc</span><br></pre></td></tr></table></figure>

<h2 id="trainer-py"><a href="#trainer-py" class="headerlink" title="trainer.py"></a>trainer.py</h2><p>导入包：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import time</span><br><span class="line">import torchsnooper</span><br></pre></td></tr></table></figure>

<p>定义训练器类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">class trainer:</span><br><span class="line">    def __init__(self, training_set, test_set, batch_size, n_epochs, model, optimizer, scheduler, loss,</span><br><span class="line">                 device, deterministic, parallel):</span><br><span class="line">        torch.backends.cudnn.deterministic &#x3D; deterministic</span><br><span class="line">        self.tr_set &#x3D; training_set</span><br><span class="line">        self.test_set &#x3D; test_set</span><br><span class="line">        self.batch_size &#x3D; batch_size</span><br><span class="line">        self.n_epochs &#x3D; n_epochs</span><br><span class="line">        self.model &#x3D; model</span><br><span class="line">        self.device &#x3D; device</span><br><span class="line">        self.parallel &#x3D; parallel</span><br><span class="line">        if parallel:</span><br><span class="line">            self.model &#x3D; nn.DataParallel(model)</span><br><span class="line">        self.model.cuda(self.device)</span><br><span class="line">        self.optimizer &#x3D; optimizer</span><br><span class="line">        self.scheduler &#x3D; scheduler</span><br><span class="line">        self.loss &#x3D; loss</span><br></pre></td></tr></table></figure>
<p>训练函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># @torchsnooper.snoop()</span><br><span class="line">def train_epoch(self, epoch):</span><br><span class="line">    start_time &#x3D; time.time()</span><br><span class="line">    self.model.train()</span><br><span class="line">    for data, target in self.tr_set:</span><br><span class="line">        data &#x3D; data.cuda(self.device)</span><br><span class="line">        target &#x3D; target.cuda(self.device)</span><br><span class="line">        self.optimizer.zero_grad()</span><br><span class="line">        output &#x3D; self.model(data)</span><br><span class="line">        loss &#x3D; self.loss(output.float(), target.long().squeeze())</span><br><span class="line">        print(loss)</span><br><span class="line">        loss.backward()</span><br><span class="line">        self.optimizer.step()</span><br><span class="line">        # self.scheduler.step()</span><br><span class="line">    all_pred, all_targets &#x3D; self.predict(self.test_set)</span><br><span class="line">    matches &#x3D; all_pred &#x3D;&#x3D; all_targets</span><br><span class="line">    true &#x3D; torch.sum(matches).float().numpy()</span><br><span class="line">    acc &#x3D; true &#x2F; len(self.test_set.dataset)</span><br><span class="line">    print(&#39;epoch&#39;+str(epoch)+&#39;:acc:&#39;+str(acc))</span><br><span class="line">    return acc</span><br></pre></td></tr></table></figure>
<p>测试函数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def predict(self, dataset):</span><br><span class="line">    self.model.eval()</span><br><span class="line">    all_pred &#x3D; torch.zeros(len(dataset.dataset))</span><br><span class="line">    all_targets &#x3D; torch.zeros(len(dataset.dataset))</span><br><span class="line">    for batch_idx, (data, target) in enumerate(dataset):</span><br><span class="line">        with torch.no_grad():</span><br><span class="line">            data &#x3D; data.cuda(self.device)</span><br><span class="line">            target &#x3D; target.cuda(self.device)</span><br><span class="line">            output &#x3D; self.model(data)</span><br><span class="line">            output &#x3D; torch.tensor(torch.argmax(output, -1).view(-1, 1), dtype&#x3D;torch.float32)</span><br><span class="line">            st &#x3D; batch_idx * self.batch_size</span><br><span class="line">            all_pred[st:st + output.shape[0]] &#x3D; output.cpu().squeeze()</span><br><span class="line">            all_targets[st:st + output.shape[0]] &#x3D; target.cpu().squeeze()</span><br><span class="line">    return all_pred, all_targets</span><br></pre></td></tr></table></figure>
<p>最后使用run函数来调用：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">def run(self, fold):</span><br><span class="line">    bestacc &#x3D; 0</span><br><span class="line">    for epoch in range(1, self.n_epochs + 1):</span><br><span class="line">        acc &#x3D; self.train_epoch(epoch)</span><br></pre></td></tr></table></figure>
<h2 id="network-py"><a href="#network-py" class="headerlink" title="network.py"></a>network.py</h2><p>基本网络结构搭建：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class network(nn.Module):</span><br><span class="line">    def __init__(self, neural_num):</span><br><span class="line">        super(network, self).__init__()</span><br><span class="line">        self.net &#x3D; nn.Sequential(</span><br><span class="line">            nn.Linear(10, neural_num),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(neural_num, 8),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, data):</span><br><span class="line">        out &#x3D; self.net(data)</span><br><span class="line">        # out &#x3D; torch.sigmoid(out)</span><br><span class="line">        return out</span><br></pre></td></tr></table></figure>

<h2 id="utils-py"><a href="#utils-py" class="headerlink" title="utils.py"></a>utils.py</h2><p>训练数据的生成与读取，以及一些常用的函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import random</span><br><span class="line">import numpy as np</span><br><span class="line">import torch</span><br><span class="line">from settings import parse_opts</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import StratifiedKFold</span><br><span class="line">from torch.utils.data import TensorDataset</span><br><span class="line">import torchsnooper</span><br></pre></td></tr></table></figure>
<p>读取setting中的参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def get_keys():</span><br><span class="line">    arg_keys &#x3D; &#123;&#125;</span><br><span class="line">    for arg_key in vars(parse_opts()).keys():</span><br><span class="line">        arg_keys[str(arg_key)] &#x3D; vars(parse_opts())[arg_key]</span><br><span class="line">    return arg_keys</span><br></pre></td></tr></table></figure>
<p>设置随机种子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def reset_rand():</span><br><span class="line">    seed &#x3D; 1000</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    random.seed(seed)</span><br></pre></td></tr></table></figure>
<p>生成训练数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">def saveDataset(path, nfold&#x3D;10):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    :param nfold:</span><br><span class="line">    :param path: the path of dataset</span><br><span class="line">    :param fold: for k-fold validation</span><br><span class="line">    :return: training, validation and test dataset</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # define the function to generate data here</span><br><span class="line"></span><br><span class="line">    raw &#x3D; pd.read_csv(path)</span><br><span class="line">    nof &#x3D; raw.shape[1] - 2</span><br><span class="line">    nod &#x3D; raw.shape[0]</span><br><span class="line">    data_x &#x3D; np.zeros((nod, nof), dtype&#x3D;np.float32)</span><br><span class="line">    data_y &#x3D; np.zeros((nod, 1), dtype&#x3D;np.int32)</span><br><span class="line">    for i, row in raw.iterrows():</span><br><span class="line">        data_x[i] &#x3D; row[1:nof + 1]</span><br><span class="line">        data_y[i] &#x3D; row[nof + 1]</span><br><span class="line">    skf &#x3D; StratifiedKFold(n_splits&#x3D;nfold, shuffle&#x3D;True)</span><br><span class="line">    fold &#x3D; [0] * len(data_x)</span><br><span class="line">    for i, (x, y) in enumerate(skf.split(data_x, data_y)):</span><br><span class="line">        for item in y:</span><br><span class="line">            fold[item] &#x3D; [i]</span><br><span class="line"></span><br><span class="line">    f &#x3D; open(&#39;&#x2F;home&#x2F;joe&#x2F;GitHub&#x2F;PytorchExample-master&#x2F;label.csv&#39;, &#39;w&#39;)</span><br><span class="line">    title &#x3D; &#39;id,&#39;</span><br><span class="line">    for i in range(nof):</span><br><span class="line">        title +&#x3D; &#39;x&#39; + str(i + 1) + &#39;,&#39;</span><br><span class="line">    title +&#x3D; &#39;y,fold\n&#39;</span><br><span class="line">    f.write(title)</span><br><span class="line"></span><br><span class="line">    for i in range(len(data_x)):</span><br><span class="line">        line &#x3D; &quot;&#123;0&#125;,&#123;1&#125;,&#123;2&#125;,&#123;3&#125;,&#123;4&#125;,&#123;5&#125;,&#123;6&#125;,&#123;7&#125;,&#123;8&#125;,&#123;9&#125;,&#123;10&#125;,&#123;11&#125;,&#123;12&#125;\n&quot;.format(i,</span><br><span class="line">                                                                                 data_x[i][0],</span><br><span class="line">                                                                                 data_x[i][1],</span><br><span class="line">                                                                                 data_x[i][2],</span><br><span class="line">                                                                                 data_x[i][3],</span><br><span class="line">                                                                                 data_x[i][4],</span><br><span class="line">                                                                                 data_x[i][5],</span><br><span class="line">                                                                                 data_x[i][6],</span><br><span class="line">                                                                                 data_x[i][7],</span><br><span class="line">                                                                                 data_x[i][8],</span><br><span class="line">                                                                                 data_x[i][9],</span><br><span class="line">                                                                                 data_y[i][0],</span><br><span class="line">                                                                                 fold[i][0])</span><br><span class="line">        f.write(line)</span><br><span class="line">    f.close()</span><br></pre></td></tr></table></figure>
<p>读取训练数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"># @torchsnooper.snoop()</span><br><span class="line">def getDataset(path, fold):</span><br><span class="line">    df &#x3D; pd.read_csv(path, engine&#x3D;&#39;python&#39;)</span><br><span class="line">    df_test &#x3D; df[df.fold &#x3D;&#x3D; fold]</span><br><span class="line">    df_train &#x3D; df[df.fold !&#x3D; fold]</span><br><span class="line">    tr_num &#x3D; len(df_train)</span><br><span class="line">    ts_num &#x3D; len(df_test)</span><br><span class="line">    nof &#x3D; df.shape[1] - 3</span><br><span class="line"></span><br><span class="line">    train_x &#x3D; torch.zeros((tr_num, nof))</span><br><span class="line">    train_y &#x3D; torch.zeros((tr_num, 1))</span><br><span class="line">    test_x &#x3D; torch.zeros((ts_num, nof))</span><br><span class="line">    test_y &#x3D; torch.zeros((ts_num, 1))</span><br><span class="line">    numtrain &#x3D; 0</span><br><span class="line">    numtest &#x3D; 0</span><br><span class="line">    for i, row in df_train.iterrows():</span><br><span class="line">        if numtrain &#x3D;&#x3D; ts_num * 9:</span><br><span class="line">            break</span><br><span class="line">        train_x[numtrain, 0] &#x3D; row.x1</span><br><span class="line">        train_x[numtrain, 1] &#x3D; row.x2</span><br><span class="line">        train_x[numtrain, 2] &#x3D; row.x3</span><br><span class="line">        train_x[numtrain, 3] &#x3D; row.x4</span><br><span class="line">        train_x[numtrain, 4] &#x3D; row.x5</span><br><span class="line">        train_x[numtrain, 5] &#x3D; row.x6</span><br><span class="line">        train_x[numtrain, 6] &#x3D; row.x7</span><br><span class="line">        train_x[numtrain, 7] &#x3D; row.x8</span><br><span class="line">        train_x[numtrain, 8] &#x3D; row.x9</span><br><span class="line">        train_x[numtrain, 9] &#x3D; row.x10</span><br><span class="line">        train_y[numtrain, 0] &#x3D; row.y</span><br><span class="line">        numtrain +&#x3D; 1</span><br><span class="line">    for i, row in df_test.iterrows():</span><br><span class="line">        if numtest &#x3D;&#x3D; ts_num:</span><br><span class="line">            break</span><br><span class="line">        test_x[numtest, 0] &#x3D; row.x1</span><br><span class="line">        test_x[numtest, 1] &#x3D; row.x2</span><br><span class="line">        test_x[numtest, 2] &#x3D; row.x3</span><br><span class="line">        test_x[numtest, 3] &#x3D; row.x4</span><br><span class="line">        test_x[numtest, 4] &#x3D; row.x5</span><br><span class="line">        test_x[numtest, 5] &#x3D; row.x6</span><br><span class="line">        test_x[numtest, 6] &#x3D; row.x7</span><br><span class="line">        test_x[numtest, 7] &#x3D; row.x8</span><br><span class="line">        test_x[numtest, 8] &#x3D; row.x9</span><br><span class="line">        test_x[numtest, 9] &#x3D; row.x10</span><br><span class="line">        test_y[numtest, 0] &#x3D; row.y</span><br><span class="line">        numtest +&#x3D; 1</span><br><span class="line">    mean_x &#x3D; train_x.mean()</span><br><span class="line">    sd_x &#x3D; train_x.std()</span><br><span class="line">    train_x &#x3D; (train_x - mean_x) &#x2F; sd_x</span><br><span class="line"></span><br><span class="line">    mean_x &#x3D; test_x.mean()</span><br><span class="line">    sd_x &#x3D; test_x.std()</span><br><span class="line">    test_x &#x3D; (test_x - mean_x) &#x2F; sd_x</span><br><span class="line"></span><br><span class="line">    trainset &#x3D; TensorDataset(train_x, train_y)</span><br><span class="line">    testset &#x3D; TensorDataset(test_x, test_y)</span><br><span class="line"></span><br><span class="line">    return trainset, testset</span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/03/10/%E6%A8%A1%E6%9D%BF/" data-id="ckm34d99l0000i3or14bifsv4" data-title="深度学习代码编写基本模板(Pytorch)" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2021/03/13/%E6%B5%8B%E8%AF%95/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          深度学习常用损失函数总结
        
      </div>
    </a>
  
  
    <a href="/2021/03/08/%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E5%B7%A5%E5%85%B7optuna/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">深度学习工具(1):自动调参工具optuna</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/03/13/%E6%B5%8B%E8%AF%95/">深度学习常用损失函数总结</a>
          </li>
        
          <li>
            <a href="/2021/03/10/%E6%A8%A1%E6%9D%BF/">深度学习代码编写基本模板(Pytorch)</a>
          </li>
        
          <li>
            <a href="/2021/03/08/%E8%87%AA%E5%8A%A8%E8%B0%83%E5%8F%82%E5%B7%A5%E5%85%B7optuna/">深度学习工具(1):自动调参工具optuna</a>
          </li>
        
          <li>
            <a href="/2021/03/08/%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/">个人博客搭建过程记录</a>
          </li>
        
          <li>
            <a href="/2021/03/07/Pytorch%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/">Pytorch踩坑记录</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2021 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>